{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdf3ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "def parse_file(name):\n",
    "    fp = open(name,'r')\n",
    "    data = fp.read()\n",
    "    fp.close()\n",
    "    data = str(data).encode('latin-1','ignore')\n",
    "    return get_tokens(data.decode())\n",
    "\n",
    "def get_tokens(data):\n",
    "    data = data.replace('\\r', '')\n",
    "    data = data.replace('\\t', ' ')\n",
    "    data = data.lower()\n",
    "    re_fun = re.compile(r'([_.->\\w]+)\\s*\\([^)]*\\)')\n",
    "    re_var = re.compile(r'\\s*([_\\d\\w]*)(\\s*)=(\\s*)[^;]*')\n",
    "\n",
    "    \n",
    "    var_idx = 0 \n",
    "    func_idx = 0\n",
    "    words = []\n",
    "    for line in data.split('\\n'):  \n",
    "\n",
    "        s = re_var.search(line)\n",
    "        if s:\n",
    "            var_idx += 1\n",
    "            var_name = s.group(1)\n",
    "            line = re.compile(r'([_\\d\\w]+\\s*=\\s*)').sub('var%d = '% var_idx, line)\n",
    "\n",
    "        s = re_fun.search(line)\n",
    "        if s:\n",
    "            got_stmt = False\n",
    "            for st in ['if','for','while']:\n",
    "                if line.find(st) >=0:\n",
    "                    got_stmt = True\n",
    "                    break\n",
    "            if not got_stmt:\n",
    "                func_idx += 1\n",
    "                func = s.group(1)\n",
    "                line = line.replace('%s' % func, 'func%d' % func_idx)\n",
    "\n",
    "        chars = ['(', ')', '{', '}', '*', '/', '+', '-', '=', ';', ',']\n",
    "        for ch in chars:\n",
    "            line = line.replace(ch, ' %s ' % ch)\n",
    "\n",
    "        if line and len(line) >= 1:         \n",
    "            for w in line.split(' '):\n",
    "                w = w.strip()\n",
    "                if w:\n",
    "                    words.append(w) \n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38e7d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm, trange\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "sys.path.append('.')\n",
    "import preprocess as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6ed7a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPP_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, wv):\n",
    "        with open(dataset, 'rb') as f:\n",
    "            self.ds = pickle.load(f)\n",
    "\n",
    "        self.maxlen = len(self.ds['vuln'])\n",
    "        self.wv = wv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds['vuln']) * 2\n",
    "\n",
    "    def get_lines(self, data):\n",
    "        return data.split('\\n')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vuln = 1\n",
    "        ds = self.ds['vuln']\n",
    "\n",
    "        if idx >= self.maxlen:\n",
    "            idx = idx % self.maxlen\n",
    "            vuln = 0\n",
    "            ds = self.ds['notvuln']\n",
    "\n",
    "\n",
    "        data = ds[idx]\n",
    "        toks = pr.get_tokens(data)\n",
    "        if len(toks) >= 100:\n",
    "            toks = toks[:100]\n",
    "        else:\n",
    "            for i in range(100-len(toks)):\n",
    "                toks.append(';')\n",
    "\n",
    "        vectors = []\n",
    "        for tok in toks:\n",
    "            vec = None\n",
    "            try:\n",
    "                vec = self.wv[tok]\n",
    "            except:\n",
    "                vec = None\n",
    "            if vec is not None:\n",
    "                vectors.extend(vec)\n",
    "\n",
    "        vectors = vectors[:3000]\n",
    "        return torch.tensor(vectors), vuln\n",
    "\n",
    "\n",
    "class MLP_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(30*100, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self,x ):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_mlp():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    use_wandb = True\n",
    "    num_epochs = 100\n",
    "    os.environ['WANDB_CONSOLE']='off'\n",
    " \n",
    "    w2v_model = Word2Vec.load(\"word2vec_gensim.model\")\n",
    "\n",
    "    train_dataset = CPP_Dataset('dataset_train.bin', w2v_model.wv)\n",
    "    test_dataset = CPP_Dataset('dataset_val.bin', w2v_model.wv)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    model = MLP_Model()\n",
    "    if use_wandb:\n",
    "        wandb.login(key='', verify=True) \n",
    "        wandb.init(project='fitzel1')\n",
    "        wandb.watch(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.00003)\n",
    "    \n",
    "    print('Started training loop, using device %s' % device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in tqdm(train_dataloader,desc='Epoch'):\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)   \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        val_loss =[]\n",
    "        val_accuracy = []\n",
    "        cal_cal = []\n",
    "        acc_acc = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_dataloader):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss.append(loss.numpy())\n",
    "                \n",
    "                preds = outputs.argmax(axis=1)\n",
    "                targets = targets.to('cpu')\n",
    "                compare = (preds == targets).type(torch.float32)\n",
    "                val_accuracy.extend(compare.numpy().tolist())\n",
    "                rec = recall_score(targets, preds)\n",
    "                acc = accuracy_score(targets, preds)\n",
    "                cal_cal.append(rec)\n",
    "                acc_acc.append(acc)\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({'loss': np.mean(val_loss), 'accuracy': np.mean(acc_acc), 'recall': np.mean(cal_cal)})\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)} \")\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.finish(quiet=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f560bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
